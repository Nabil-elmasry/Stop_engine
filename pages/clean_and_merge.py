
import streamlit as st
import pandas as pd
import os
import glob
import base64

st.set_page_config(page_title="ğŸ§¹ Ø¯Ù…Ø¬ ÙˆØªÙ†Ø¸ÙŠÙ Ù…Ù„ÙØ§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª", layout="wide")
st.title("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ ÙˆØªØ¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª")

st.markdown("""
### ğŸ“‚ Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø¹Ù…Ù„:
ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø®ØªÙŠØ§Ø± Ø¥Ø­Ø¯Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚ØªÙŠÙ†:
- âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙÙƒÙˆÙƒØ© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ù…Ù† Ù…Ù„Ù ZIP (Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ `data/extracted_files/`)
- ğŸ“¥ Ø£Ùˆ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª CSV ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ù‡Ù†Ø§ ÙÙŠ Ø­Ø§Ù„Ø© ÙˆØ¬ÙˆØ¯ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ ØµÙØ­Ø© ZIP
""")

# âœ… Ø§Ø®ØªÙŠØ§Ø± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
method = st.radio("Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª:", ["ğŸ“ Ù…Ù† Ù…Ø¬Ù„Ø¯ ZIP Ø§Ù„Ù…ÙÙƒÙˆÙƒ", "ğŸ“¤ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª CSV ÙŠØ¯ÙˆÙŠÙ‹Ø§"])

dfs = []
total_rows = 0

if method == "ğŸ“ Ù…Ù† Ù…Ø¬Ù„Ø¯ ZIP Ø§Ù„Ù…ÙÙƒÙˆÙƒ":
    folder_path = "data/extracted_files/"
    if not os.path.exists(folder_path):
        st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø¬Ù„Ø¯ data/extracted_files. Ø§Ø±ÙØ¹ ZIP Ø£ÙˆÙ„Ø§Ù‹.")
    else:
        csv_files = glob.glob(os.path.join(folder_path, "*.csv"))
        if not csv_files:
            st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª CSV Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯.")
        else:
            st.markdown(f"ğŸ” Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©: **{len(csv_files)}**")
            for i, file in enumerate(csv_files):
                try:
                    df = pd.read_csv(file)
                    dfs.append(df)
                    total_rows += len(df)
                    if i < 3:
                        st.success(f"ğŸ“„ {os.path.basename(file)} - Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ: {len(df)}")
                except Exception as e:
                    st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© {file}: {e}")

elif method == "ğŸ“¤ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª CSV ÙŠØ¯ÙˆÙŠÙ‹Ø§":
    uploaded_files = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª CSV", type="csv", accept_multiple_files=True)
    if uploaded_files:
        for i, uploaded_file in enumerate(uploaded_files):
            try:
                df = pd.read_csv(uploaded_file)
                dfs.append(df)
                total_rows += len(df)
                if i < 3:
                    st.success(f"ğŸ“„ {uploaded_file.name} - Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ: {len(df)}")
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© {uploaded_file.name}: {e}")
    else:
        st.info("ğŸ“‚ Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ø£ÙŠ Ù…Ù„ÙØ§Øª Ø¨Ø¹Ø¯.")

# âœ… Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø¯Ù…Ø¬ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ
if dfs:
    combined_df = pd.concat(dfs, ignore_index=True)
    combined_df.dropna(axis=1, how='all', inplace=True)
    combined_df = combined_df.loc[:, ~combined_df.columns.duplicated()]

    os.makedirs("data", exist_ok=True)
    output_path = "data/merged_clean.csv"
    combined_df.to_csv(output_path, index=False)

    st.success(f"âœ… ØªÙ… Ø§Ù„Ø¯Ù…Ø¬ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ - Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {len(combined_df)}")
    st.write("ğŸ“‹ Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 ØµÙÙˆÙ:")
    st.dataframe(combined_df.head())

    with open(output_path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode()
        href = f'<a href="data:file/csv;base64,{b64}" download="merged_clean.csv">â¬‡ï¸ Ø§Ø¶ØºØ· Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¯Ù…Ø¬</a>'
        st.markdown("### ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù")
        st.markdown(href, unsafe_allow_html=True)
else:
    st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø¯Ù…Ø¬ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯.")